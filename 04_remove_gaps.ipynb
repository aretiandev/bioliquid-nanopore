{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Gaps\n",
    "\n",
    "This script removes gaps in the reads and the genome. It contains the following steps:\n",
    "\n",
    "- Loading and cleaning read data and reference genome data\n",
    "- Visualizing overlap between reads\n",
    "- Collapsing the regions where there is empty data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Clean Reference Genome\n",
    "\n",
    "Info: https://lh3.github.io/2017/11/13/which-human-reference-genome-to-use\n",
    "\n",
    "S3 nanopore directory:\n",
    "\n",
    "s3cmd get --recursive s3://aretian-genomics/nanopore/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull reference genome from S3\n",
    "# !s3cmd get s3://aretian-genomics/nanopore/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz\n",
    "\n",
    "# !gunzip GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz\n",
    "\n",
    "# Index reference genome\n",
    "# !samtools faidx GCA_000001405.15_GRCh38_no_alt_analysis_set.fna\n",
    "\n",
    "# Select chromosomes or regions\n",
    "# !samtools faidx GCA_000001405.15_GRCh38_no_alt_analysis_set.fna chr17 > chr17_selected.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Chromosome 17\n",
    "\n",
    "Extract Chr17 from reference genome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique characters: ['N', 'A', 'S', 'T', 'Y', 'C', 'G', 'K', 'W', 'R']\n",
      "Selected chromosome from reference genome is 83257441 BP long\n"
     ]
    }
   ],
   "source": [
    "# Read in fasta file: remove line breaks and header\n",
    "def read_fasta_genome(fasta_file,chromosome_header):\n",
    "    clean_data = fasta_file.read().replace(\"\\n\", \"\")\n",
    "    clean_data = clean_data.replace(chromosome_header,\"\") # get rid of header\n",
    "\n",
    "    return clean_data\n",
    "\n",
    "with open('../data/processed/chr17_selected.fa') as f: # update path if needed\n",
    "    ref_genome = read_fasta_genome(f,'>chr17')\n",
    "\n",
    "# See https://www.bioinformatics.org/sms/iupac.html for IUPAC nucleotide codes\n",
    "\n",
    "print(f\"Unique characters: {list(set(ref_genome))}\") \n",
    "\n",
    "print(f\"Selected chromosome from reference genome is {len(ref_genome)} BP long\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Clean Reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samtools view --> format of output: http://samtools.github.io/hts-specs/SAMv1.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ../data/run1/processed/run1_chr17_pompe_reads.csv does not exist: '../data/run1/processed/run1_chr17_pompe_reads.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6d2e674b78b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#!samtools view bioliquid_chr17_pompe.bam | head -n 500 > bioliquid_chr17_pompe_500reads.txt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnanopore_reads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/run1/processed/run1_chr17_pompe_reads.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/genomics/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/genomics/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/genomics/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/genomics/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/genomics/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File ../data/run1/processed/run1_chr17_pompe_reads.csv does not exist: '../data/run1/processed/run1_chr17_pompe_reads.csv'"
     ]
    }
   ],
   "source": [
    "#!view -c bioliquid_chr17_pompe.bam\n",
    "#!samtools view bioliquid_chr17_pompe.bam | head -n 500 > bioliquid_chr17_pompe_500reads.txt\n",
    "\n",
    "nanopore_reads = pd.read_csv('../data/run1/processed/run1_chr17_pompe_reads.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort and get ID\n",
    "nanopore_reads = nanopore_reads.sort_values(by='POS',ascending=True) # sort based on starting index of reads\n",
    "nanopore_reads['ID'] = np.nan\n",
    "# Get columns of interest\n",
    "nanopore_reads = nanopore_reads[['ID', 'QNAME', 'FLAG', 'RNAME', 'POS', 'MAPQ', 'CIGAR', 'RNEXT', 'PNEXT','TLEN', 'SEQ', 'QUAL']]\n",
    "# Drop missing values\n",
    "nanopore_reads = nanopore_reads.loc[nanopore_reads['SEQ'] != '*'] # drop any rows without a proper nucleotide sequence\n",
    "# Reset index and save ID\n",
    "nanopore_reads = nanopore_reads.reset_index()\n",
    "nanopore_reads['ID'] = nanopore_reads.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count and plot overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_reads_length():\n",
    "    for ID in nanopore_reads.index:\n",
    "        print(f\"Leftmost index --> {nanopore_reads.loc[ID,'POS']}, Read length --> {len(nanopore_reads.loc[ID,'SEQ'])}\")\n",
    "\n",
    "def create_overlap_df():\n",
    "    end_index = max(nanopore_reads['POS']) + len(nanopore_reads.loc[nanopore_reads['POS'].idxmax(),'SEQ'])\n",
    "    start_index = min(nanopore_reads['POS'])\n",
    "    index_range = end_index-start_index\n",
    "\n",
    "    read_overlap = np.zeros((len(nanopore_reads),index_range)) # empty matrix for reads\n",
    "\n",
    "    for ID in nanopore_reads.index:\n",
    "    #     print(f\"Adding raad cover for read {ID+1}: Index-->{nanopore_reads.loc[ID,'POS']}, length-->{len(nanopore_reads.loc[ID,'SEQ'])}\")\n",
    "        start = nanopore_reads.loc[ID,'POS']-start_index\n",
    "        end = start+len(nanopore_reads.loc[ID,'SEQ'])\n",
    "        read_overlap[ID,start:end] = 1\n",
    "\n",
    "    summary = read_overlap.sum(axis=0)\n",
    "    \n",
    "    overlap_df = pd.DataFrame(data=summary,index=range(start_index,end_index), columns=['overlap_count'])\n",
    "    overlap_df['position'] = overlap_df.index\n",
    "    overlap_df['isempty']=overlap_df['overlap_count']==0\n",
    "    \n",
    "    return overlap_df\n",
    "\n",
    "def count_empty_regions():\n",
    "    win_length=10000\n",
    "    emptycount = 0\n",
    "    emptyregioncounter = 0\n",
    "\n",
    "    for i in overlap_df.index:\n",
    "\n",
    "        if overlap_df.loc[i,'isempty']==False:\n",
    "            emptycount = 0\n",
    "            continue\n",
    "\n",
    "        emptycount += 1\n",
    "\n",
    "        if emptycount >= win_length:\n",
    "            emptyregioncounter +=1\n",
    "\n",
    "        if i%100000==0:\n",
    "            print(f\"Loop: {i}\")\n",
    "\n",
    "    print(f\"There are at most {emptyregioncounter} regions with lengths larger than {win_length}\")\n",
    "\n",
    "def plot_overlap(overlap_df):\n",
    "    fig, ax = plt.subplots(dpi=150)\n",
    "    # plt.plot(overlap_df[:40000]['position'],overlap_df[:40000]['overlap_count'])\n",
    "    # plt.plot(overlap_df[:40000]['position'],overlap_df[:40000]['overlap_count'])\n",
    "    # plt.plot(overlap_df.loc[1000000:,'position'],overlap_df.loc[1000000:,'overlap_count'])\n",
    "    # plt.plot(overlap_df['position'],overlap_df['overlap_count'])\n",
    "    plt.plot(overlap_df['position'],overlap_df['isempty'])\n",
    "    plt.xlabel('Nucleotide Position')\n",
    "    plt.ylabel('# Reads Overlapping')\n",
    "\n",
    "# count_empty_regions()\n",
    "# overlap_df = create_overlap_df()\n",
    "# plot_overlap(overlap_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Length and Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nanopore_reads' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5e9607dd300d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check read length statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnanopore_reads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SEQ_LEN'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnanopore_reads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SEQ'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnanopore_reads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'END_POS'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnanopore_reads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'POS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnanopore_reads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SEQ_LEN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Read length statistics:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnanopore_reads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SEQ_LEN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nanopore_reads' is not defined"
     ]
    }
   ],
   "source": [
    "# Check read length statistics\n",
    "nanopore_reads['SEQ_LEN'] = nanopore_reads['SEQ'].apply(lambda x: len(x))\n",
    "nanopore_reads['END_POS'] = nanopore_reads['POS']+nanopore_reads['SEQ_LEN']\n",
    "print(f\"Read length statistics:\")\n",
    "nanopore_reads['SEQ_LEN'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read position statistics:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    1.080000e+03\n",
       "mean     2.550694e+07\n",
       "std      1.445399e+06\n",
       "min      2.293697e+07\n",
       "25%      2.419741e+07\n",
       "50%      2.647332e+07\n",
       "75%      2.661930e+07\n",
       "max      2.699905e+07\n",
       "Name: POS, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check read pos statistics\n",
    "print(f\"Read position statistics:\")\n",
    "nanopore_reads['POS'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trim reference genome chromosome to locus of interest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collapse Gaps "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract location of interest from Reference Genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected focus are for chromosome from reference genome is 4085413 BP long\n"
     ]
    }
   ],
   "source": [
    "ref_genome = ref_genome[min(nanopore_reads['POS']):max(nanopore_reads['END_POS'])]\n",
    "print(f\"Selected focus are for chromosome from reference genome is {len(ref_genome)} BP long\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset start and end positions based on location of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = min(nanopore_reads['POS'])\n",
    "\n",
    "# archive old positions\n",
    "nanopore_reads['ORIG_POS'] = nanopore_reads['POS']\n",
    "nanopore_reads['ORIG_END_POS'] = nanopore_reads['END_POS']\n",
    "\n",
    "# shift positions\n",
    "nanopore_reads['POS'] = nanopore_reads['POS']-shift\n",
    "nanopore_reads['END_POS'] = nanopore_reads['END_POS']-shift\n",
    "\n",
    "nanopore_reads = nanopore_reads.reset_index() # to make the next step easier\n",
    "nanopore_reads = nanopore_reads[['ID', 'QNAME', 'FLAG', 'RNAME', 'POS', 'MAPQ', 'CIGAR','RNEXT', 'PNEXT', 'TLEN', 'SEQ', 'QUAL', 'SEQ_LEN', 'END_POS','ORIG_POS', 'ORIG_END_POS']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 69 gaps.\n"
     ]
    }
   ],
   "source": [
    "confirmed_gaps = [] # Collect gaps in list\n",
    "max_end_pos = 0 # Store end position of longest read\n",
    "\n",
    "for index in nanopore_reads.index:\n",
    " \n",
    "    try:\n",
    "        current_read_end = nanopore_reads.loc[index,'END_POS']\n",
    "        \n",
    "        if current_read_end <= max_end_pos: # Current read is redundant\n",
    "            continue\n",
    "            \n",
    "        # Current read is not redundant, then update max_end_pos\n",
    "        max_end_pos = current_read_end\n",
    "        \n",
    "        next_read_start = nanopore_reads.loc[index+1,'POS']\n",
    "\n",
    "        delta = next_read_start-current_read_end\n",
    "\n",
    "        if delta <= 0: # There is overlap, so no problem\n",
    "            continue \n",
    "        elif delta > 0: # There is a gap\n",
    "            # Calculate gap based on original position\n",
    "            gap_start = nanopore_reads.loc[index  ,'ORIG_END_POS']\n",
    "            gap_end   = nanopore_reads.loc[index+1,'ORIG_POS']\n",
    "            orig_gap = (gap_start+1,gap_end-1)\n",
    "            confirmed_gaps.append(orig_gap) # Add gap to list\n",
    "            \n",
    "            # Calculate gap based on adjusted positions\n",
    "            gap = (current_read_end+1,next_read_start-1)\n",
    "            \n",
    "            # Shift remaining reads to the left\n",
    "            shift = gap[1]-gap[0]+1 \n",
    "            # Check shift is the same with original position data\n",
    "            shift_check = orig_gap[1]-orig_gap[0]+1\n",
    "            if shift!=shift_check:\n",
    "                print(f\"Found difference: orig_gap: {orig_gap}, gap: {gap}.\")\n",
    "                print(f\"Difference: orig_gap {shift_check}, gap {shift}\")\n",
    "            try:\n",
    "                nanopore_reads.loc[(index+1):,'POS'] = nanopore_reads.loc[index+1:,'POS']-shift\n",
    "                nanopore_reads.loc[(index+1):,'END_POS'] = nanopore_reads.loc[index+1:,'END_POS']-shift\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "    except:\n",
    "        pass\n",
    "            \n",
    "print(f\"There are {len(confirmed_gaps)} gaps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if gaps overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_gap_end = 0\n",
    "for gap in confirmed_gaps:\n",
    "    gap_start = gap[0]\n",
    "    \n",
    "    if gap_start <= previous_gap_end: # we have a problem\n",
    "        print(f\"Found an intersection in gap {gap}.\")\n",
    "    \n",
    "    # Update gap_end for next iteration\n",
    "    previous_gap_end = gap[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust reference_genome based on removed indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 69 gaps = 1,052,700 basepairs.\n",
      "Reference genome length before collapsing gaps: 4,085,413 basepairs.\n",
      "Final genome length should be: 3,032,713\n",
      "Final genome length after collapsing gaps: 3,032,713 basepairs.\n"
     ]
    }
   ],
   "source": [
    "# Reset confirmed_gaps to start at 0\n",
    "shift = min(nanopore_reads['ORIG_POS'])\n",
    "orig_confirmed_gaps = [(gap[0]-shift, gap[1]-shift) for gap in confirmed_gaps]\n",
    "\n",
    "indices_to_remove = []\n",
    "for gap in orig_confirmed_gaps:\n",
    "    for i in range(gap[0],gap[1]+1):\n",
    "        indices_to_remove.append(i)\n",
    "\n",
    "print(f\"Removing {len(confirmed_gaps)} gaps = {len(indices_to_remove):,} basepairs.\")\n",
    "print(f\"Reference genome length before collapsing gaps: {len(ref_genome):,} basepairs.\")\n",
    "print(f\"Final genome length should be: {len(ref_genome)-len(indices_to_remove):,}\")\n",
    "\n",
    "final_genome = ''\n",
    "segment_start = 0\n",
    "\n",
    "for gap in orig_confirmed_gaps:\n",
    "\n",
    "    gap_start = gap[0]\n",
    "    gap_end = gap[1]\n",
    "    \n",
    "    # Cut segment until next gap\n",
    "    new_segment = ref_genome[segment_start:gap_start]\n",
    "    \n",
    "    # Append to final genome\n",
    "    final_genome = final_genome + new_segment\n",
    "    \n",
    "    # Start of next segment\n",
    "    segment_start = gap_end + 1\n",
    "    \n",
    "# Add last segment\n",
    "new_segment = ref_genome[segment_start:]\n",
    "final_genome = final_genome + new_segment\n",
    "\n",
    "print(f\"Final genome length after collapsing gaps: {len(final_genome):,} basepairs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Reference Genome\n",
    "initial_position = min(nanopore_reads['ORIG_POS'])\n",
    "final_genome_dict = {'initial_position':initial_position, 'reference_genome': final_genome}\n",
    "with open('../data/processed/reference_genome_chr17_nogaps.json', 'w') as f:\n",
    "    json.dump(final_genome_dict,f)\n",
    "\n",
    "# Save Nanopore Reads\n",
    "nanopore_reads.to_csv('../data/run1/processed/run1_chr17_pompe_reads_nogaps.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRA CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Gaps V2\n",
    "\n",
    "This version identifies gaps in reads by running two loops. It was discarded because the current version does the same job with just one loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirmed_gaps2 = []\n",
    "# for index in nanopore_reads.index:\n",
    "#     try:\n",
    "#         current_read_end = nanopore_reads.loc[index,'END_POS']\n",
    "        \n",
    "#         gaps = []\n",
    "#         for index2 in nanopore_reads.index:\n",
    "#             try:\n",
    "#                 if index == index2: # it's the same read\n",
    "#                     continue\n",
    "\n",
    "# #                 next_read_start = nanopore_reads.loc[index+1,'POS']\n",
    "#                 next_read_start = nanopore_reads.loc[index2,'POS']\n",
    "\n",
    "#                 delta = next_read_start-current_read_end\n",
    "\n",
    "\n",
    "#                 if delta < 0: # There is overlap or it's a previous read\n",
    "#                     continue \n",
    "#                 elif delta==0: # There is a single nucleotide overlap\n",
    "#                     continue\n",
    "#                 elif delta > 0: # There is a gap\n",
    "#                     gaps.append((current_read_end+1,next_read_start-1)) # range between the values\n",
    "#             except:\n",
    "#                 pass\n",
    "            \n",
    "                \n",
    "                \n",
    "#         minimum_gap = min(gaps, key = lambda x: x[1]-x[0])\n",
    "#         confirmed_gaps2.append(minimum_gap)\n",
    "        \n",
    "#     except:\n",
    "#         pass\n",
    "\n",
    "# print(f\"There are {len(confirmed_gaps2)} gaps\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collapse gaps\n",
    "\n",
    "This older version takes longer to delete gaps since it iterates over a list instead of using the indexes of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ref_genome_list = list(ref_genome)\n",
    "# for index in sorted(indices_to_remove, reverse=True):\n",
    "#     del ref_genome_list[index]\n",
    "# ref_genome = ''.join(ref_genome_list)\n",
    "\n",
    "# print(f\"Reference genome length after collapsing gaps: {len(ref_genome):,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Genomics",
   "language": "python",
   "name": "genomics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
