{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56d7ad5b-8b2f-4156-8de2-5aa0b6bd6291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12 - LONG READS\n",
    "#\n",
    "# This script takes the information in tagged_reads.csv and combines the reads into long reads. The script is based on 12_long_reads.ipynb\n",
    "#\n",
    "# INPUTS:\n",
    "#   run_number\n",
    "#   disease\n",
    "#   tagged_reads.csv\n",
    "# \n",
    "# OUTPUTS:\n",
    "#   tagged_long_reads.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9270d55-083c-4ade-971b-b65dc17c15fa",
   "metadata": {},
   "source": [
    "# Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77843d63-8e63-4a16-800e-a4ac65ed4714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcad6e3c-a033-4bf5-9337-792a5d162131",
   "metadata": {},
   "source": [
    "# Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71c06636-6031-4ac5-8265-d7751469d941",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_num=3\n",
    "run_number=f\"run{run_num}\"\n",
    "chrom=\"chr11\"\n",
    "dis=\"sca\"\n",
    "\n",
    "# Parameters\n",
    "expected_gap_fraction = 0.5\n",
    "\n",
    "# Setup\n",
    "chrom_dis=f\"{chrom}_{dis}\"\n",
    "rootdir=f\"/mnt/aretian/genomics/nanopore\"\n",
    "datadir=f\"/mnt/aretian/genomics/nanopore/{run_number}\"\n",
    "homedir=\"/home/fer/genomics/bioliquid-nanopore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fd77527-1686-4d82-a9a2-8239463d8743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "12 - CREATE LONG READS)\n",
      "Run: 3, disease: sca.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('')\n",
    "print('----------------------------------------------------------------------')\n",
    "# print(f'12 - CREATE LONG READS (__file__})')\n",
    "print(f'12 - CREATE LONG READS)')\n",
    "print(f\"Run: {run_num}, disease: {dis}.\")\n",
    "print('')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b682f0-7d01-4910-a88b-c3b327ec648c",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "659b0d3b-8032-4904-b71a-11e432822b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{datadir}/{run_number}_{chrom_dis}_tagged_reads.csv')\n",
    "original_columns = df.columns\n",
    "df = df.rename(columns={'startpos':'orig_pos'})\n",
    "shift = min(df['orig_pos'])\n",
    "df['pos'] = df['orig_pos'] - shift\n",
    "df['seq_len']= df['read'].apply(lambda x: len(x))\n",
    "df['end_pos']=df['pos']+df['seq_len']-1\n",
    "df['sample'] = df['samplename'].str[-1].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399a5400-79be-48b2-b6b0-670bd514b28c",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7457bbcf-6e63-43a2-a945-6fbb9f67b13b",
   "metadata": {},
   "source": [
    "## Create Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02401531-c11c-4ce8-b865-205ae7ab396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bins(df):\n",
    "    total_length = max(df['end_pos'])\n",
    "    reads_0 = df[df['sample']==0]\n",
    "    reads_1 = df[df['sample']==1]\n",
    "\n",
    "    # Number of reads\n",
    "    n_0=len(reads_0)\n",
    "    n_1=len(reads_1)\n",
    "\n",
    "    # Average length\n",
    "    mean_length = df['seq_len'].mean()\n",
    "    mean_length_0 = reads_0['seq_len'].mean()\n",
    "    mean_length_1 = reads_1['seq_len'].mean()\n",
    "\n",
    "    # Total bins\n",
    "    expected_gap = mean_length*expected_gap_fraction\n",
    "    bin_length = round(mean_length + expected_gap)\n",
    "    n_bins_exact = total_length/bin_length \n",
    "    n_bins = round(n_bins_exact)\n",
    "\n",
    "    # Bins in  person0\n",
    "    n_long_reads_0 = n_0/n_bins\n",
    "    # Bins in person1\n",
    "    n_long_reads_1 = n_1/n_bins\n",
    "    \n",
    "    # Force at least 10 long_reads\n",
    "    n_long_read_threshold = 10\n",
    "    if n_long_reads_0<n_long_read_threshold:\n",
    "        n_long_reads_0=n_long_read_threshold\n",
    "        n_bins_0 = round(n_0/n_long_reads_0)\n",
    "        \n",
    "    if n_long_reads_1<n_long_read_threshold:\n",
    "        n_long_reads_1=n_long_read_threshold\n",
    "        n_bins_1 = round(n_1/n_long_reads_1)\n",
    "        \n",
    "    try:\n",
    "        if n_bins_0 < n_bins_1:\n",
    "            n_bins = n_bins_0\n",
    "            bin_length = round(total_length/n_bins)\n",
    "            n_bins_exact = total_length/bin_length \n",
    "            print(f\"Too few reads for person0. Setting n_bins={n_bins} to get at least {n_long_read_threshold} long reads.\")\n",
    "        elif n_bins_0 > n_bins_1:\n",
    "            n_bins = n_bins_1\n",
    "            bin_length = round(total_length/n_bins)\n",
    "            n_bins_exact = total_length/bin_length \n",
    "            print(f\"Too few reads for person1. Setting n_bins={n_bins} to get at least {n_long_read_threshold} long reads.\")\n",
    "    except:\n",
    "        try:\n",
    "            n_bins = n_bins_0\n",
    "            bin_length = round(total_length/n_bins)\n",
    "            n_bins_exact = total_length/bin_length \n",
    "            print(f\"Too few reads for person0. Setting n_bins={n_bins} to get at least {n_long_read_threshold} long reads.\")\n",
    "        except:\n",
    "            try:\n",
    "                n_bins = n_bins_1\n",
    "                bin_length = round(total_length/n_bins)\n",
    "                n_bins_exact = total_length/bin_length \n",
    "                print(f\"Too few reads for person1. Setting n_bins={n_bins} to get at least {n_long_read_threshold} long reads.\")\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "            \n",
    "    print(\"\")\n",
    "    print(f\"OPTIMAL BIN SIZE AND NUMBER\")\n",
    "    print(\"\")\n",
    "    print(f\"Total length of region:     {total_length:,.0f}\")\n",
    "    print(f\"Avg read length:               {mean_length:,.2f}\")\n",
    "    print(f\"Avg read length + {expected_gap_fraction*100:,.0f}% padd:    {mean_length+expected_gap:,.2f}\")\n",
    "    print(f\"Bin length:                    {bin_length:,.0f}\")\n",
    "    print(f\"total_length/bin_length:           {n_bins_exact:,.2f}\")\n",
    "    print(f\"Number of bins:                    {n_bins:,.2f} --> last bin is {'shorter' if (n_bins>n_bins_exact) else 'longer'}.\")\n",
    "    print(\"\")\n",
    "    print(f\"ESTIMATED # OF LONG READS PER PERSON\")\n",
    "    print(\"\")\n",
    "    print(f\"               Count       Avg Length    N of long reads (est)\")\n",
    "    print(f\"person0        {n_0:,.0f}       {mean_length:,.0f}        {n_long_reads_0:,.0f}\")   \n",
    "    print(f\"person1        {n_1:,.0f}       {mean_length_0:,.0f}        {n_long_reads_1:,.0f}\")\n",
    "    print(f\"Full sample    {len(df):,.0f}       {mean_length_1:,.0f}        {n_long_reads_0 + n_long_reads_1:,.0f}\")\n",
    "\n",
    "    # Parameters\n",
    "    bins = []\n",
    "\n",
    "    last_bin_end = -1\n",
    "    for i in range(int(np.floor(n_bins))):\n",
    "        bin_start = last_bin_end + 1\n",
    "        bin_end   = bin_start + bin_length - 1\n",
    "        bins.append([bin_start, bin_end])\n",
    "        last_bin_end = bin_end\n",
    "\n",
    "    # Gap\n",
    "    bin_agg_length = n_bins * bin_length\n",
    "    gap = total_length - bin_agg_length\n",
    "    print(\"\")\n",
    "    print(f\"ADJUSTMENT FOR LAST BIN\")\n",
    "    print(\"\")\n",
    "    print(f\"Total length:         {total_length:,.0f}\")\n",
    "    print(f\"Bin aggregate length: {bin_agg_length:,.0f}\")\n",
    "    print(f\"Difference:              {gap:,.0f}\")\n",
    "\n",
    "    # Last bin length\n",
    "    last_bin_length = bin_length + gap\n",
    "    print(f\"Bin length:              {bin_length:,.0f}\")\n",
    "    print(f\"Last bin length:         {last_bin_length:,.0f}\")\n",
    "\n",
    "    # Adjust last bin length\n",
    "    bins[-1][1]=bins[-1][0]+last_bin_length-1\n",
    "    \n",
    "    return bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a90d0f-8d95-4b2d-9bdb-5339bacee6b4",
   "metadata": {},
   "source": [
    "## Assign reads to bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f034471-c7e7-4887-b8b0-34bae9397173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assign_reads_to_bins(df, bins, selected_person):\n",
    "# Returns person_reads with the 'bin' column of bin membership\n",
    "    \n",
    "    print(\"\")\n",
    "    print(f\"Selected person: person{selected_person}.\")\n",
    "    print(\"\")\n",
    "    print(\"Assigning reads to bins.\")\n",
    "\n",
    "    if   selected_person == 0:\n",
    "        reads_0 = df[df['sample']==0]\n",
    "        person_reads = reads_0.copy()\n",
    "    elif selected_person == 1:\n",
    "        reads_1 = df[df['sample']==1]\n",
    "        person_reads = reads_1.copy()\n",
    "\n",
    "    # Count empty bins\n",
    "    empty_bins = 0\n",
    "    empty_bins_list = []\n",
    "\n",
    "    # Initialize bin column with empty lists\n",
    "    person_reads['bin']=np.empty((len(person_reads), 0)).tolist()\n",
    "\n",
    "    # Lambda function to append bin membership to list\n",
    "    def append_bin(read, bin):\n",
    "        read['bin'].append(bin)\n",
    "        return read\n",
    "\n",
    "    # Add bin membership column to person_reads df\n",
    "    for n, bin in enumerate(bins):\n",
    "\n",
    "        # Get reads in bin\n",
    "        read_starts_inside = (person_reads['pos']    >bin[0]) & (person_reads['pos']    <bin[1])\n",
    "        read_ends_inside   = (person_reads['end_pos']>bin[0]) & (person_reads['end_pos']<bin[1])\n",
    "        read_covers        = (person_reads['pos']    <bin[0]) & (person_reads['end_pos']>bin[1])\n",
    "\n",
    "        overlaps_bin = (read_starts_inside | read_ends_inside | read_covers)\n",
    "\n",
    "        # Count empty bins\n",
    "        if overlaps_bin.sum() == 0:\n",
    "            empty_bins = empty_bins + 1\n",
    "            empty_bins_list.append(n)\n",
    "            continue\n",
    "\n",
    "        # Append bin number to bin column\n",
    "        person_reads.loc[overlaps_bin].apply(lambda x: append_bin(x, n), axis=1)\n",
    "\n",
    "    print(f\"Done. Reads with no assigned bin: {person_reads['bin'].isna().sum()}\")\n",
    "    print(f\"There are {empty_bins} empty bins: {empty_bins_list}\")\n",
    "    \n",
    "    return person_reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c2dcf1-5e6d-470a-867b-83f97952c1c2",
   "metadata": {},
   "source": [
    "## Create long reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf04ec28-15f0-4ac7-b193-eff0ac581774",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_long_reads(person_reads):\n",
    "# Populated the person_reads dataframe with the long_read column\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Creating long reads.\")\n",
    "    \n",
    "    max_bin_n = max(person_reads['bin'].max())\n",
    "    \n",
    "    # List of bins to iterate over\n",
    "    search_bins = list(range(max_bin_n+1))\n",
    "\n",
    "    # Initialize long read membership\n",
    "    person_reads['long_read'] = np.nan\n",
    "    # Track reads that are already assigned\n",
    "    person_reads['assigned'] = False\n",
    "\n",
    "    long_read_number = 0\n",
    "\n",
    "    n_unassigned = len(person_reads)\n",
    "    \n",
    "    while n_unassigned > 0:\n",
    "        # While there are unassigned reads\n",
    "\n",
    "        n_unassigned = len(person_reads) - person_reads['assigned'].sum()\n",
    "        progress = (1-n_unassigned/len(person_reads))*100\n",
    "\n",
    "        for n in search_bins:\n",
    "        # Run bin loop assigning reads\n",
    "\n",
    "            # Get reads in bin\n",
    "            bin_reads_boolean = person_reads.apply(lambda x: n in x['bin'], axis=1)\n",
    "\n",
    "            # If all reads in bin have been assigned, skip and ignore bin in the future\n",
    "            if (bin_reads_boolean & ~person_reads['assigned']).any() == False:\n",
    "                search_bins.remove(n)\n",
    "                continue\n",
    "                \n",
    "            print(f\"\\rLong read: {long_read_number:3.0f}. Bin: {n:3.0f}. Unassigned: {n_unassigned:5.0f}. Progress: {progress:3.0f}%\", end=\"\", flush=True)\n",
    "            \n",
    "            # Get reads in bin that are not assigned\n",
    "            bin_reads = person_reads.loc[bin_reads_boolean & ~person_reads['assigned']]\n",
    "\n",
    "            # Get first read_id\n",
    "            first_read_id = bin_reads['read_id'].unique()[0]\n",
    "            \n",
    "            # Assign first read_id (with all STRs) to long read\n",
    "            person_reads.loc[person_reads['read_id']==first_read_id, 'long_read'] = long_read_number\n",
    "            # Record assignment\n",
    "            person_reads.loc[person_reads['read_id']==first_read_id, 'assigned'] = True\n",
    "        \n",
    "        # Go to the next long read\n",
    "        long_read_number += 1\n",
    "        \n",
    "#         if long_read_number > 20:\n",
    "#             break\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Done.\")\n",
    "    \n",
    "    return person_reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726fcfdf-843c-4b52-aebd-23ea8404d722",
   "metadata": {},
   "source": [
    "## Trim long reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d370fc3-7ef2-47c4-84fa-5ea75b656879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_long_reads(person0_reads, person1_reads, desired_n_long_reads, n0_extract=None, n1_extract=None, ratio='manual'):\n",
    "\n",
    "    # Set defaults for number of reads to be created\n",
    "    if ratio == 'manual':\n",
    "        # Default Option 1: Set manually\n",
    "        n0_extract_default = 15\n",
    "        n1_extract_default = 10\n",
    "    elif ratio == 'proportional':\n",
    "        # Default Option 2: Proportional to read counts\n",
    "        n_long_reads0 = len(person0_reads)\n",
    "        n_long_reads1 = len(person1_reads)\n",
    "        n_long_reads = n_long_reads0 + n_long_reads1\n",
    "        share_long_reads0 = n_long_reads0/n_long_reads\n",
    "        share_long_reads1 = n_long_reads1/n_long_reads\n",
    "        n0_extract_default = round(share_long_reads0*desired_n_long_reads)\n",
    "        n1_extract_default = desired_n_long_reads - n0_extract_default\n",
    "        print(f'Proportional ratio: {n0_extract_default}, {n1_extract_default}.')\n",
    "    \n",
    "    if n0_extract is None:\n",
    "        n0_extract = n0_extract_default\n",
    "    if n1_extract is None:\n",
    "        n1_extract = n1_extract_default\n",
    "        \n",
    "    # Raise error\n",
    "    if desired_n_long_reads != n0_extract + n1_extract:\n",
    "        raise ValueError(f'n0_extract and n1_extract should add up to {desired_n_long_reads}')\n",
    "\n",
    "    # Extract reads\n",
    "    extract_list0 = list(person0_reads['long_read'].value_counts().iloc[:n0_extract].index)\n",
    "    extract_list1 = list(person1_reads['long_read'].value_counts().iloc[:n1_extract].index)\n",
    "    person0_reads_trim = person0_reads.loc[person0_reads['long_read'].isin(extract_list0)]\n",
    "    person1_reads_trim = person1_reads.loc[person1_reads['long_read'].isin(extract_list1)]\n",
    "    \n",
    "    return person0_reads_trim, person1_reads_trim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2451eb-bc33-4da4-ac4a-d26fc6ca7e6a",
   "metadata": {},
   "source": [
    "## Fill in gaps between long reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee89f4b3-1add-4487-ab91-76b67fc6683b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fill_gaps_within_person(person_reads_trim):\n",
    "    \n",
    "    # Get longest long_read\n",
    "    longest_read_n = person_reads_trim['long_read'].value_counts().index[0]\n",
    "    longest_read =   person_reads_trim.loc[person_reads_trim['long_read']==longest_read_n]\n",
    "    \n",
    "    # Get all STRs in longest long_read\n",
    "    longest_read_strs = set(longest_read['str_id'].unique())\n",
    "\n",
    "    # Loop prep: Get total number of long reads\n",
    "    n_long_reads = person_reads_trim['long_read'].nunique()\n",
    "    # Loop prep: initialize dataframe to populate\n",
    "    person_reads_full_within = person_reads_trim.copy()\n",
    "    \n",
    "    for long_read_n in range(1,n_long_reads):\n",
    "\n",
    "        # Get nth longest long_read\n",
    "        nth_longest_read_n = person_reads_trim['long_read'].value_counts().index[long_read_n]\n",
    "        nth_longest_read   = person_reads_trim.loc[person_reads_trim['long_read']==nth_longest_read_n]\n",
    "\n",
    "        # Get all reads in nth longest long_read\n",
    "        nth_longest_read_strs = set(nth_longest_read['str_id'].unique())\n",
    "\n",
    "        # Calculate difference with longest read\n",
    "        str_difference = longest_read_strs.difference(nth_longest_read_strs)\n",
    "\n",
    "        # Get missing reads\n",
    "        new_reads = longest_read.loc[longest_read['str_id'].isin(str_difference)].copy()\n",
    "        new_reads['long_read'] = nth_longest_read_n\n",
    "\n",
    "        # Add to dataframe\n",
    "        person_reads_full_within = pd.concat([person_reads_full_within, new_reads])\n",
    "    \n",
    "    return person_reads_full_within"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845b8c52-f7ea-4a4d-8d0d-9b6b8a5a5829",
   "metadata": {},
   "source": [
    "## Plot Long reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ba27487-8e2b-40da-83b7-8d4f0cbb016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_long_reads(person_reads):\n",
    "    \n",
    "    print(\"Drawing points in long reads.\")\n",
    "    \n",
    "    # Loop prep: Get list and number of long reads\n",
    "    long_reads_list = list(person_reads['long_read'].unique())\n",
    "    n_long_reads = int(person_reads['long_read'].nunique())\n",
    "    long_read_counter = 1\n",
    "\n",
    "    # Loop prep: Initialize long read collection\n",
    "    long_read_collection = []\n",
    "\n",
    "    # Loop prep: Calculate total_length\n",
    "    total_length = max(person_reads['end_pos'])\n",
    "    \n",
    "    for long_read_n in long_reads_list:\n",
    "        \n",
    "        long_read_binary = []\n",
    "\n",
    "        print(f\"\\rProcessing long read: {long_read_counter} of {n_long_reads}\", end=\"\", flush=True)\n",
    "\n",
    "        selected_long = person_reads.loc[person_reads['long_read']==long_read_n].copy()\n",
    "\n",
    "        for point in range(0,total_length+1,10000):\n",
    "            after_start =  selected_long['pos']< point\n",
    "            before_end  =  point < selected_long['end_pos']\n",
    "            is_in_read  = (after_start & before_end).any()\n",
    "\n",
    "            value_to_append = 1 if is_in_read else np.nan\n",
    "            long_read_binary.append(value_to_append)\n",
    "\n",
    "        long_read_collection.append(long_read_binary)\n",
    "        \n",
    "        long_read_counter += 1\n",
    "\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Plotting.\")\n",
    "\n",
    "    long_read_plot = plt.subplots(figsize=(20,10))\n",
    "    x = range(len(long_read_collection[0]))\n",
    "\n",
    "    for i in range(len(long_read_collection)):\n",
    "        long_read_binary = [x * (i+1) for x in long_read_collection[i]]\n",
    "        plt.scatter(x, long_read_binary)\n",
    "        \n",
    "    return long_read_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8343d30-7085-4128-a288-794223298bbd",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ead3f4-1af7-4147-9cfc-ca186839223e",
   "metadata": {},
   "source": [
    "## Create Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e188922-f648-4988-b44e-a282af31e024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too few reads for person1. Setting n_bins=12 to get at least 10 long reads.\n",
      "\n",
      "OPTIMAL BIN SIZE AND NUMBER\n",
      "\n",
      "Total length of region:     3,941,766\n",
      "Avg read length:               26,282.75\n",
      "Avg read length + 50% padd:    39,424.12\n",
      "Bin length:                    328,480\n",
      "total_length/bin_length:           12.00\n",
      "Number of bins:                    12.00 --> last bin is longer.\n",
      "\n",
      "ESTIMATED # OF LONG READS PER PERSON\n",
      "\n",
      "               Count       Avg Length    N of long reads (est)\n",
      "person0        337       26,283        10\n",
      "person1        119       29,148        10\n",
      "Full sample    456       18,169        20\n",
      "\n",
      "ADJUSTMENT FOR LAST BIN\n",
      "\n",
      "Total length:         3,941,766\n",
      "Bin aggregate length: 3,941,760\n",
      "Difference:              6\n",
      "Bin length:              328,480\n",
      "Last bin length:         328,486\n"
     ]
    }
   ],
   "source": [
    "bins = create_bins(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf93f9f-0b53-4783-a762-fcaa30158f12",
   "metadata": {},
   "source": [
    "## Assign reads to bins and create long reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdd70c75-428f-4228-b152-8d8105185863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected person: person0.\n",
      "\n",
      "Assigning reads to bins.\n",
      "Done. Reads with no assigned bin: 0\n",
      "There are 0 empty bins: []\n",
      "\n",
      "Creating long reads.\n",
      "Long read:  17. Bin:   1. Unassigned:     2. Progress:  99%\n",
      "Done.\n",
      "\n",
      "Selected person: person1.\n",
      "\n",
      "Assigning reads to bins.\n",
      "Done. Reads with no assigned bin: 0\n",
      "There are 0 empty bins: []\n",
      "\n",
      "Creating long reads.\n",
      "Long read:  12. Bin:  11. Unassigned:     1. Progress:  99%\n",
      "Done.\n",
      "\n",
      "Person 0 long reads: 17\n",
      "Person 1 long reads: 12\n"
     ]
    }
   ],
   "source": [
    "selected_person = 0\n",
    "person0_reads = assign_reads_to_bins(df, bins, selected_person)\n",
    "person0_reads = create_long_reads(person0_reads)\n",
    "\n",
    "selected_person = 1\n",
    "person1_reads = assign_reads_to_bins(df, bins, selected_person)\n",
    "person1_reads = create_long_reads(person1_reads)\n",
    "\n",
    "print(\"\")\n",
    "print(f\"Person 0 long reads: {person0_reads['long_read'].max():,.0f}\")\n",
    "print(f\"Person 1 long reads: {person1_reads['long_read'].max():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786cbe42-5fc1-4635-a871-1cf9811870db",
   "metadata": {},
   "source": [
    "## Trim Long Reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6995073c-ebfb-492c-8931-0729ce3f9f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportional ratio: 18, 7.\n"
     ]
    }
   ],
   "source": [
    "# person0_reads_trim, person1_reads_trim = trim_long_reads(person0_reads, person1_reads, 25, 15, 10)\n",
    "person0_reads_trim, person1_reads_trim = trim_long_reads(person0_reads, person1_reads, 25, ratio='proportional')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55b445e-fa81-437b-8071-e46c4d3cfe1f",
   "metadata": {},
   "source": [
    "## Fill gaps within person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abb65357-5386-4712-93fd-425e6ef7904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "person0_reads_full_within = fill_gaps_within_person(person0_reads_trim)\n",
    "person1_reads_full_within = fill_gaps_within_person(person1_reads_trim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706151bc-875c-4c4c-87d7-eed88698842c",
   "metadata": {},
   "source": [
    "## Fill gaps between mother and child\n",
    "\n",
    "2. In the difference between 1100 and 700\n",
    "\n",
    "    Child --> ALT\n",
    "    \n",
    "    Mother --> REF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4724fce7-cc51-4d23-83fa-fe3dc8fb2d07",
   "metadata": {},
   "source": [
    "## Concatenate output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d510bace-7b45-41c9-9d66-fdcdcb30e515",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_reads = pd.concat([person0_reads_full_within, person1_reads_full_within])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9f9699-3cde-4759-b07f-fd8d427f83eb",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67693ef1-378e-4ea4-8154-60fbdbd38a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_reads0_plot = plot_long_reads(person0_reads_full_within)\n",
    "plt.savefig(f'cluster_plots/{run_number}_{chrom_dis}_long_reads_person0.png', bbox_inches='tight')\n",
    "\n",
    "long_reads1_plot = plot_long_reads(person1_reads_full_within)\n",
    "plt.savefig(f'cluster_plots/{run_number}_{chrom_dis}_long_reads_person1.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc8a2c9-8f02-4932-a0b5-02c565fcfa8a",
   "metadata": {},
   "source": [
    "# Create output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44d5c406-2710-424c-90a8-6afe0367d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename and keep columns as original file\n",
    "person_reads_out = person_reads.copy()\n",
    "\n",
    "# Create long read ID\n",
    "person_reads_out['long_read_id'] = person_reads_out['samplename'] + '-' + person_reads_out['long_read'].astype(int).astype(str)\n",
    "\n",
    "# Replace new read ID\n",
    "person_reads_out = person_reads_out.drop(columns=['read_id'])\n",
    "person_reads_out = person_reads_out.rename(columns={'long_read_id':'read_id'})\n",
    "\n",
    "# Rename columns as original\n",
    "person_reads_out = person_reads_out.rename(columns={'orig_pos':'startpos'})\n",
    "person_reads_out = person_reads_out[original_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13af325-ad9e-4d0c-8e92-1a7f484d47f9",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "547ca8c1-6d0e-49c5-a8a5-ec2a0ecf0226",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_reads_out.to_csv(f'{datadir}/{run_number}_{chrom_dis}_long_tagged_reads.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef728c4f-9848-466c-9f0f-4779882ffece",
   "metadata": {},
   "source": [
    "# EXTRA CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ff39f0-84cb-4315-b24b-3654710d7b02",
   "metadata": {},
   "source": [
    "# Edit Boolean Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7c17ffa-9167-464f-bf1b-12e1c587612d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # # Read file\n",
    "# filename='run1_chr11_bool_tagged_reads.csv'\n",
    "# mydf = pd.read_csv(f'{datadir}/{filename}')\n",
    "# import subprocess\n",
    "\n",
    "# # Create matrix to append\n",
    "# mydf_append=1-mydf.iloc[:,1:]\n",
    "\n",
    "# mydf_append.columns = mydf_append.columns+'-ALT'\n",
    "\n",
    "# # Add columns in right order\n",
    "# mydf_out = pd.DataFrame(mydf.iloc[:,0])\n",
    "# for i in range(mydf_append.shape[1]):\n",
    "#     mydf_out = pd.concat([mydf_out, mydf.iloc[:,i+1]], axis=1)\n",
    "#     mydf_out = pd.concat([mydf_out, mydf_append.iloc[:,i]], axis=1)\n",
    "\n",
    "# # Save\n",
    "# mydf_out.to_csv(f'{datadir}/{filename}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
